---
permalink: /
title: "About Me (Updated: 05-Mov-2024)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


My name is Wang Kehan. I obtained my Ph.D. in 2024 from Tsinghua University. Subsequently, I joined *China Telecom* Cloud Co., Ltd. as a senior researcher. During my doctoral studies, I interned at *Huawei* and *Samsung Research China-Beijing (SRC-B)*. My research covers AI for science(Machine Learning Molecular Dynamics, AI for Materials), large language models, and new-generation cloud computing technologies. I have published papers in journals including JPCL.

You can contact me at wangkehan2018@yeah.net.

Education and Employment
======
[07/2024]-[Now], Senior Researcher, China Telecom Cloud Co., Ltd.,Beijing, China

[09/2019]-[06/2024], PhD student (Mechanical Engineering, Ph.D. thesis title: Research on Structural Superlubricity Simulation Based on Machine Learning.), Tsinghua University, Beijing, China

[07/2022]-[04/2023], AI research Intern (SRC-B Best Intern Award), Samsung Research China-Beijing (SRC-B), Beijing, China

[06/2021]-[08/2021], AI Engineering Intern, Huawei, Dongguan, China

[09/2015]-[07/2019], Bachelor’s degree (Material Physics), University of Science and Technology Beijing, Beijing, China



Research Interests
======

More introductions to my current and previous research projects can be found in papers.

Following are some related keywords often appeared in my papers:

*Computational Physics and Chemistry*: quantum chemistry, MD simulation, multi-scale calculation, DFT…

*AI for Science*: machine learning potentials, generative AI for molecular generation, Large Language Models …
Materials: battery, OLED, semiconductors, capacitor, aluminum foil, fluorine chemicals…

*Tribology and Mechanics*:Friction, Wear, Lubrication, Stress, Strain...

*New-generation cloud computing technologies*: Large language model, log analysis, software engineering,...

I am committed to applying various intelligent technologies to a wide range of fields, including natural sciences, software engineering, and new-generation cloud computing technologies. While pursuing accuracy, a good computational method should provide new physical insights for key issues and guide product design.

I am particularly interested in the following topics:

1.AI4S
======

My interests in AI4S include machine learning potential , automatic differentiation algorithms, deep generative models, graph theory, and their applications into interface modelling, enhanced sampling method, force field optimization, molecular generation, material property prediction and chemical reaction networks, etc.



Particularly, I developed a method with my co-workers to use multi-fidelity training data of JAX-ReaxFF—an automatic differentiation method to parameterize ReaxFF and DFT to reduce the computational costs in training SchNet and MACE based machine learning potentials. The method was employed to study a diverse range of properties of 2D semiconductor materials, see 2024 JPCL: https://pubs.acs.org/doi/abs/10.1021/acs.jpclett.3c03080.
![image](https://github.com/user-attachments/assets/f196fcc4-dc85-4dfa-996c-410db5143d63)
![image](https://github.com/user-attachments/assets/548fbeab-676e-4e15-a2e1-ec4d34e7d7b7)


2.Tribology
======

I formally published a paper in the journal Frontiers in Chemistry(https://www.frontiersin.org/articles/10.3389/fchem.2021.807630/full) titled "Negative or positive? Loading area dependent correlation between friction and normal load in structural superlubricity." In this study, we discovered a counterintuitive phenomenon: as pressure increases, friction actually decreases. We conducted MD simulations with data analysis and statistical analysis on morphological and energetic data, built models, effectively predicted frictional forces, and proposed effective methods for reducing friction.

![image](https://github.com/user-attachments/assets/5897c85d-e290-4359-8e15-1383141aaae6)


3.New-generation cloud computing technologies
======

In the field of cloud computing, the automated analysis of log data is crucial for operations and maintenance teams. This study introduces LLMDPP, a novel log parser that leverages Large Language Models (LLMs) and Determinantal Point Process (DPP) sampling techniques to enhance the efficiency and accuracy of online log parsing. LLMDPP transforms raw log messages into structured log templates through fewshot learning, thereby simplifying the processing and analysis of log data.The study explores the accuracy of LLMDPP in log parsing tasks and compares the effectiveness of different encoding functions (TF-IDF and Flan-T5-small embedding layer) in DPP sampling. Experimental results show that LLMDPP outperforms traditional methods in both Global Accuracy (GA) and Parsing Accuracy (PA), with the semantic information encoding function performing better when the number of samples is low. Furthermore, we simulated an online scenario to evaluate the parsing effectiveness of different sampling methods on unseen
log datasets. The results indicate that the DPP sampling method has an advantage in maintaining sample diversity and fairness, which can improve parsing accuracy.

![image](https://github.com/user-attachments/assets/67172333-293d-4037-a5f0-bf6e6c40895e)



Awards and Social Activities
======
[10/2023]  Tsinghua University Weihai Scholarship
[09/2023]   Best Presentation at NanoMT Conference
[10/2022]    Tsinghua University General Talent Scholarship
[12/2021]  Second Prize of "RONG" Scholarship from the Big Data Research Center, School of Software, Tsinghua University
[01/2022] - Present    Outstand Volunteer for "Data Faction" WeChat Public Account, School of Software, Tsinghua University: Engaged in translation and proofreading work in the translation group, translated and proofread more than 20 articles, totaling over 50,000 words. Many articles have exceeded 5,000 reads.
—Participated in the publication of original articles such as "Google JAX Boosts Scientific Computing," "Resonating with the Times, AI Aids in Industrial Defect Detection," "A Preliminary Exploration of Machine Learning in Molecular Dynamics Field Conference Papers," "A Quick Read of Computational Chemistry Field Conference Papers in One Article," and "Knowledge Distillation: Unlocking the Wisdom Code of Large Models."
[06/2019]   Outstanding Graduate of Beijing City
[10/2018]  National Scholarship
[10/2017]   National Scholarship
[10/2016]   National Scholarship
[10/2016]   Second Prize in the National College English Competition


